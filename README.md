# Teste Estagi√°rio - Intuitive Care

## üìå Vis√£o Geral
### **Projeto-Teste para vaga de est√°gio**

Este projeto transforma dados brutos da ANS em informa√ß√µes validadas, enriquecidas e agregadas.
Os dados s√£o armazenados em um banco de dados, acess√≠veis via API e frontend interativo, al√©m de conter
documenta√ß√£o completa e decis√µes t√©cnicas justificadas

O projeto consiste em 4 etapas:
  -  01 - INTEGRA√á√ÉO COM API P√öBLICA
  -  02 - TRANSFORMA√á√ÉO E VALIDA√á√ÉO DE DADOS
  -  03 - BANCO DE DADOS E AN√ÅLISE
  -  04 - API E INTERFACE WEB
  
Cada uma das etapas cont√©m subt√≥picos com instru√ß√µes espec√≠ficas e direcionadas para o que fazer

## üõ†Ô∏è Estrutura do Projeto

O projeto foi desenvolvido utilizando diferentes tecnologias a fim de facilitar o trajeto at√© o objetivo final

### Python

Respons√°vel por grande parte de processamento das 4 etapas do projeto incluindo:

- Leitura e escrita de arquivos CSV
- Padroniza√ß√£o, valida√ß√£o, filtragem, organiza√ß√£o e an√°lise de dados
- Integra√ß√£o de bases por meio de merge/join
- Tratamento de inconsist√™ncias
- Gera√ß√£o de relat√≥rios finais ap√≥s os tratamentos necess√°rios

### Bibliotecas utilizadas:

- pandas ‚Üí manipula√ß√£o e an√°lise de dados
- pathlib ‚Üí organiza√ß√£o e portabilidade dos caminhos do projeto (padr√£o do python)
- re ‚Üí tratamento de strings e normaliza√ß√£o de campos (padr√£o do python)
- fastapi ‚Üí framework para desenvolvimento de APIs REST de alta performance
- uvicorn ‚Üí servidor ASGI utilizado para executar a aplica√ß√£o FastAPI
- sqlalchemy ‚Üí ORM e engine de conex√£o com o banco de dados
- pymysql ‚Üí driver MySQL utilizado pelo SQLAlchemy
- python-dotenv ‚Üí carregamento de vari√°veis de ambiente a partir de arquivos .env
- pydantic ‚Üí valida√ß√£o, tipagem e serializa√ß√£o de dados
- starlette ‚Üí framework base utilizado internamente pelo FastAPI
- numpy ‚Üí suporte a opera√ß√µes num√©ricas e integra√ß√£o com o pandas
- mysql ‚Üí connector-python ‚Üí driver alternativo para conex√£o com MySQL

---
### MySQL

Utilizado somente na Etapa 03 para estruturar e organizar os dados importados dos arquivos CSV. Suas principais fun√ß√µes nesta etapa foram:

- Armazenamento estruturado das bases consolidadas
- Execu√ß√£o de consultas anal√≠ticas diretamente no banco
- Importa√ß√£o e manipula√ß√£o de dados via arquivos CSV
- Cria√ß√£o de queries DDL para estruturar as tabelas
- Queries de importa√ß√£o para inserir dados de arquivo CSV nas tabelas
- Queries anal√≠ticas para an√°lise e gera√ß√£o de relat√≥rios

--- 


# üìÇ Organiza√ß√£o dos Arquivos

A estrutura do projeto foi organizada de forma modular para facilitar manuten√ß√£o, leitura e evolu√ß√£o:

### Intuitive_Care/Etapa01/
- ```src/``` -> scripts Python respons√°veis pelo processamento
- ```data/``` -> subpastas com arquivos CSV relativos ao nome de cada planilha
- ```Planilhas_originais/``` -> arquivos baixado da API p√∫blica com dados relativos de 3 trimestres
- ```Planilhas_tratadas/``` -> arquivos p√≥s primeira modifica√ß√£o da Etapa 01 **("planilha_filtrada_sinistros.csv")** e para merge **("Relatorio_cadop.csv")**
- ```Resultado/``` -> arquivo p√≥s-merge **("planilha_filtrada_sinistros.csv" e "Relatorio_cadop.csv")**
- ```ResultadoFinal/``` -> arquivo final organizado para ser usado na Etapa 02 **("consolidado_despesas.csv")**
- ```README.md``` -> documentar decis√µes t√©cnicas e trade-offs da Etapa 01

### Intuitive_care02/Etapa02/ 
- ```consolidado_Etapa01/``` -> arquivo **"consolidado_despesas.csv"** da Etapa01 para realizar opera√ß√µes
- ```dados_cadastrais/``` -> arquivo **"Relatorio_cadop.csv"** para merge/join
- ```pos_merge/``` ‚Üí arquivos gerados ap√≥s a integra√ß√£o das bases 
- ```planilha_final/``` ‚Üí resultado dos arquivos agregados, ordenados, verificados e tratados
- ```src/``` -> scripts Python respons√°veis pelo processamento
- ```README.md``` -> documentar decis√µes t√©cnicas e trade-offs da Etapa02

### Intuitive_care03/Etapa03/
- ```data/``` -> arquivos CSV utilizados
- ```src``` -> arquivos SQL para cria√ß√£o das diferentes queries 
- ```README.md``` -> documentar decis√µes t√©cnicas e trade-offs da Etapa03

> ‚ö†Ô∏è Observa√ß√£o: Testei diferentes arquiteturas de modulariza√ß√£o e a estrat√©gia usada na Etapa 03 foi a melhor. A organiza√ß√£o com apenas data/ e src/ deixa o projeto mais objetivo e limpo, sem polui√ß√£o visual de m√∫ltiplas pastas e arquivos desnecess√°rios 

### Intuitive_care03/Etapa04/
- ```src``` -> arquivos Python para cria√ß√£o da API 
- ```README.md``` -> documentar decis√µes t√©cnicas e trade-offs da Etapa04


---


## üéØ Descri√ß√£o das Etapas

  - **Etapa 01 ‚Äì Integra√ß√£o com API P√∫blica**

-> Processamento e Consolida√ß√£o de dados

-> Buscar e baixar os arquivos de Demonstra√ß√µes Cont√°beis dos √∫ltimos 3 trimestres dispon√≠veis na API P√∫blica: https://dadosabertos.ans.gov.br/FTP/PDA/ 

-> Juntar os dados dos 3 trimestres em um √∫nico arquivo e filtrar apenas os dados que contenham ```Despesas com Eventos/Sinistros```

-> Criar e adicionar colunas espec√≠ficas e tratar inconsist√™ncias

-> Gerar o arquivo final ```consolidado_despesas.csv``` ap√≥s todo tratamento

---

  - **Etapa 02 - Transforma√ß√£o e Valida√ß√£o de Dados**

-> Valida√ß√£o, enriquecimento e agrega√ß√£o de dados

-> Validar CNPJ, Raz√£o Social e valores num√©ricos positivos no ```consolidado_despesas.csv```

-> Baixar arquivo ```Relatorio_cadop.csv``` de Dados Cadastrais das Operadoras Ativas em: https://dadosabertos.ans.gov.br/FTP/PDA/operadoras_de_plano_de_saude_ativas/ 

-> Realizar merge entre ```consolidado_despesas.csv``` e ```Relatorio_cadop.csv``` usando CNPJ como chave

-> Criar e adicionar colunas adicionais, agrupar dados por colunas espec√≠ficas

-> Executar c√°lculos, ordenar e organizar os dados

-> Gerar arquivo final ```despesas_agregadas.csv``` ap√≥s todas as opera√ß√µes

---

  - **Etapa 03 - Banco de Dados e An√°lise**

-> Utilizar os arquivos ```consolidado_despesas.csv```, ```despesas_agregadas.csv``` e ```Relatorio_cadop.csv```

-> Criar queries DDL para estruturar tabelas necess√°rias para cada arquivo CSV

-> Aplicar normaliza√ß√µes e padroniza√ß√µes nos dados

-> Criar queries de importa√ß√£o para inserir dados nas tabelas, atentando-se ao encoding e tratamento de inconsist√™ncias

-> Desenvolver queries anal√≠ticas para responder perguntas de neg√≥cios

---

  - **Etapa 04 - Teste de API e Interface Web**

-> Utilizar os dados do banco de dados criado na Etapa 03 e criar uma API com Flask ou FastAPI

-> Criar rotas espec√≠ficas para a API, escolher estrat√©gia de pagina√ß√£o e estrutura de resposta

-> Desenvolver uma interface web usando Vue.js que interaja com a API em Python

-> Documentar a API demonstrando todas as rotas e exemplos de requisi√ß√µes e respostas esperadas

---


## ‚ñ∂Ô∏è Como executar

O projeto √© dividido em 4 etapas (ETL ‚Üí Enriquecimento ‚Üí Banco ‚Üí API). Execute na ordem para garantir que os arquivos e tabelas existam

**1. Para in√≠cio de tudo:**

Garanta os pr√©-requisitos:
  - Python 3.9 ou superior

  - MySQL 8.0 ou superior
  - Cliente MySQL (MySQL Workbench ou via terminal)
  - ```bash 
    python -m venv venv
    
    pip install -r requirement.txt

Com isso, o ambiente virtual (venv) estar√° criado e as depend√™ncias do projeto ser√£o instaladas

---
**2. Etapa 01: Integra√ß√£o + Consolida√ß√£o dos Dados (Python)**

**Prepara√ß√£o:**

- Coloque os arquivos CSV brutos na pasta ```Intuitive_Care/Etapa01/data/Planilhas_originais/```
- Garanta que as pastas de sa√≠da existam

- **Execu√ß√£o:**
  ```bash
  cd Intuitive_Care/Etapa01
  python -m src.filtrar_&_juntar_csv
  python -m src.merge_de_arquivos
  python -m src.organizar_planilha

---
**3. Etapa 02: Valida√ß√£o + Join com Dados Cadastrais (Python)**

- Confirme que voc√™ tem:

    - ```consolidado_despesas.csv``` (gerado na Etapa 01)

    - CSV cadastral (ex: Relatorio_cadop.csv) dentro de: ```Intuitive_care02/Etapa02/dados_cadastrais/```

    - O consolidado deve estar em: ```Intuitive_care02/Etapa02/consolidado_Etapa01/```

- **Execu√ß√£o:**
  ```bash
  cd Intuitive_care02/Etapa02
  python -m src.validacoes
  python -m src.merge_arquivos
  python -m src.agregacao_dados 

---
**4. Etapa 03: Banco de Dados e An√°lises (MySQL)**

- Nesta etapa voc√™ cria as tabelas no MySQL, importa os CSVs e executa queries anal√≠ticas

- **Configura√ß√£o:**
    Crie o banco e selecione ele:
    ```bash 
    CREATE DATABASE intuitive_care_database;

    USE intuitive_care_database;

- **Execu√ß√£o:**

  - Criar tabelas (DDL) 
  
  Rodar o arquivo ```Intuitive_care03/Etapa03/src/queries_DDL_tabelas.sql```

  - Importar CSVs para as tabelas

  Rodar o arquivo ```Intuitive_care03/Etapa03/src/queries_importar_csv.sql```

  - Rodar queries anal√≠ticas

  Rodar o arquivo ```Intuitive_care03/Etapa03/src/queries_analiticas.sql```

---

**5. Etapa 04: API (FastAPI)**
- Nesta etapa voc√™ sobe a API para consultar operadoras, hist√≥rico de despesas e dados paginados diretamente do banco

- Crie um arquivo ```.env.exemple``` em ```Intuitive_care04/Etapa04/.env``` com essas informa√ß√µes dentro:
  ```bash 
  DB_HOST=localhost
  DB_PORT=3306
  DB_USER=root
  DB_PASSWORD=sua_senha
  DB_NAME=intuitive_care_database 

- Crie os arquivos Python dentro src

- **Execu√ß√£o:**
  ```bash 
  cd Intuitive_care04/Etapa04
  uvicorn src.main:app --reload

Ap√≥s iniciar a API, acesse a rota ```/docs``` para visualizar a documenta√ß√£o interativa (Swagger) e testar todas as rotas dispon√≠veis


> **‚ö†Ô∏è Observa√ß√£o:** Dentro do reposit√≥rio, em cada pasta, se encontra um README relatando decis√µes t√©cnicas e trade-offs necess√°rios sobre cada Etapa do projeto













